{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fe = Feature_engineering()\n",
    "woe = WoE()\n",
    "corr_methods = Correlation_methods()\n",
    "plot_phik = Phik_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (15000, 29)\n",
      "test size: (10000, 28)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "id_col = test['id']\n",
    "\n",
    "df = fe.feature_engineering(df=df)\n",
    "df = woe.features_with_woe(df=df)\n",
    "test = fe.feature_engineering(df=test)\n",
    "test = woe.features_with_woe(df=test)\n",
    "cols_to_drop = fe.features_to_drop(df=df, target='smoking', threshold=0.15)\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "test = test.drop(columns=cols_to_drop)\n",
    "test['lfs_cat'] = test['lfs_cat'].fillna(1)\n",
    "\n",
    "\n",
    "print(\"train size:\", df.shape)\n",
    "print(\"test size:\", test.shape)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['smoking'])\n",
    "y = df['smoking']\n",
    "seed = 1\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categoric columnlarni scale qilmaslik uchun\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), \n",
    "        np.arange(15))],\n",
    "    remainder='passthrough'  # Keeps the last 3 features unchanged\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_logis = Pipeline([\n",
    "    ('scaler', preprocessor),  \n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "pipeline_dt = Pipeline([\n",
    "    ('scaler', preprocessor),  \n",
    "    ('decisiontree', DecisionTreeClassifier(random_state=seed,\n",
    "                                            min_samples_split = 2, \n",
    "                                            min_samples_leaf = 10,\n",
    "                                            max_features = 'sqrt', \n",
    "                                            max_depth = 10))\n",
    "])\n",
    "pipeline_bc = Pipeline([\n",
    "    ('bagging', BaggingClassifier(DecisionTreeClassifier(random_state=seed, max_depth=10),\n",
    "                                  n_estimators=199, \n",
    "                                  random_state=seed, \n",
    "                                  max_samples=.85))\n",
    "])\n",
    "pipeline_rf = Pipeline([\n",
    "    ('randomForest', RandomForestClassifier(n_estimators= 199,\n",
    "                                            min_samples_split= 20,\n",
    "                                            min_samples_leaf= 5,\n",
    "                                            max_features= 'sqrt',\n",
    "                                            max_depth= 20,\n",
    "                                            bootstrap=True,\n",
    "                                            random_state=seed))\n",
    "])\n",
    "pipeline_svc = Pipeline([\n",
    "    ('scaler', preprocessor),\n",
    "    ('svc', SVC(random_state=seed, probability=True))\n",
    "])\n",
    "\n",
    "estimators = [\n",
    "    ('logistic', pipeline_logis),\n",
    "    ('decisionTree', pipeline_dt),\n",
    "    ('bagging', pipeline_bc),\n",
    "    ('randomForest', pipeline_rf),\n",
    "    # ('svc', pipeline_svc)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87852932 0.88756322 0.87994279 0.88658259 0.8890092 ]\n",
      "STD: 0.004250133887023619\n",
      "Mean ROC-AUC: 0.8843254266244402\n"
     ]
    }
   ],
   "source": [
    "stacking = StackingClassifier(estimators=estimators,\n",
    "                              final_estimator=RandomForestClassifier(n_estimators= 400,\n",
    "                                                                    min_samples_split= 20,\n",
    "                                                                    min_samples_leaf= 5,\n",
    "                                                                    max_features= 'sqrt',\n",
    "                                                                    max_depth= 20,\n",
    "                                                                    bootstrap=True,\n",
    "                                                                    random_state=seed),\n",
    "                              cv=skf,\n",
    "                              passthrough=True,\n",
    "                              n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(stacking, X, y, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print(cv_scores)\n",
    "print('STD:', cv_scores.std())\n",
    "print('Mean ROC-AUC:', np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction for kaggle comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = StackingClassifier(estimators=estimators,\n",
    "                              final_estimator=RandomForestClassifier(n_estimators= 400,\n",
    "                                                                    min_samples_split= 20,\n",
    "                                                                    min_samples_leaf= 5,\n",
    "                                                                    max_features= 'sqrt',\n",
    "                                                                    max_depth= 20,\n",
    "                                                                    bootstrap=True,\n",
    "                                                                    random_state=seed),\n",
    "                              cv=skf,\n",
    "                              passthrough=True,\n",
    "                              n_jobs=-1\n",
    ")\n",
    "stacking.fit(X, y)\n",
    "y_pred = stacking.predict_proba(test)[:, 1]\n",
    "\n",
    "# pd.DataFrame({'id':id_col, 'smoking':y_pred}).to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
